---
title: "[Short Paper] Multi-modal perception dataset of in-water objects for autonomous surface vehicles"
collection: publications
category: published
permalink: /publication/2024-04-multimodal-perception-dataset
abstract: 'This paper introduces the first publicly accessible multi-modal perception dataset for autonomous maritime navigation, focusing on in-water obstacles within the aquatic environment to enhance situational awareness for Autonomous Surface Vehicles (ASVs). This dataset, consisting of diverse objects encountered under varying environmental conditions, aims to bridge the research gap in marine robotics by providing a multi-modal, annotated, and ego-centric perception dataset, for object detection and classification. We also show the applicability of the proposed datasetâ€™s framework using deep learning-based open-source perception algorithms that have shown success. We expect that our dataset will contribute to development of the marine autonomy pipeline and marine (field) robotics. Please note this is a work-in-progress paper about our on-going research that we plan to release in full via future publication.'
date: 2024-04
venue: 'Workshop on Field Robotics at 2024 IEEE International Conference on Robotics and Automation (ICRA).'
paperurl: 'https://arxiv.org/abs/2404.18411'
authors: 'Mingi Jeong, Arihant Chadda, Ziang Ren, Luyang Zhao, Haowen Liu, Monika Roznere, <b>Aiwei Zhang</b>, Yitao Jiang, Sabriel Achong, Samuel Lensgraf, Alberto Quattrini Li'
citation: 'M. Jeong*, A. Chadda*, Z. Ren, L. Zhao, H. Liu, M. Roznere, A. Zhang, Y. Jiang, S. Achong, S. Lensgraf, and A. Quattrini Li. Multi-modal Perception Dataset of In-water Objects for Autonomous Surface Vehicles. Workshop on Field Robotics at 2024 IEEE International Conference on Robotics and Automation (ICRA). [Best Paper Award Nominee] (* equal contribution)'
---
